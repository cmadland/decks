[["index.html", "Presentations Welcome", " Presentations Colin Madland Last updated: 2023-03-02 Welcome Please use the table of contents on the left to navigate through my presentations. "],["otessa22---assessment-and-digital-technology-in-higher-education.html", " 1 OTESSA22 - Assessment and Digital Technology in Higher Education Introduction Technology-Mediated Assessment in Higher Education Themes and Research Directions Questions? Comments? References", " 1 OTESSA22 - Assessment and Digital Technology in Higher Education Introduction Colin Madland, PhD Candidate, University of Victoria Slides - https://bit.ly/otessa22-b Find me on the web… Twitter Mastodon Presented Online at OTESSA22, May 17, 2022 I acknowledge that the land where I currently live and work remains the traditional, ancestral, and unceded land of the syilx (silks) people, whose historical stewardship of and connections to the land continue to today. I am grateful to be an uninvited guest on this land. To learn more, please visit the Westbank First Nation website. Figure 1. Author’s bicycle overlooking Okanagan Lake. Hypothes.is If you haven’t already, feel free to sign up here as we will use hypothes.is later. Also, if you have questions or comments, please annotate to your heart’s content! Background This review is guided by four research questions: What are the major themes or patterns in the literature related to approaches to assessment in higher education? What are the major themes or patterns in the literature related to the impact of technology on assessment in higher education? What gaps exist in the literature related to approaches to assessment in technology-mediated higher education? Scriven, 1967 Scriven, M. (1967). The methodology of evaluation. In B. O. Smith (Ed.), Perspectives of curriculum evaluation. Rand McNally distinction between formative and summative Bloom, 1968 Bloom, B. (1968). Learning for Mastery. Instruction and Curriculum. Regional Education Laboratory for the Carolinas and Virginia, Topical Papers and Reprints, Number 1. Evaluation Comment, 1(2), 12. Incorporated formative and summative distinction into his ideas about mastery learning Mislevy, 1994 Mislevy, R. J. (1994). Test theory reconcieved. ETS Research Report Series, 1994(1), i–38. https://doi.org/10/gjm236 test theory is machinery for reasoning from students’ behavior to conjectures about their competence, as framed in a particular conception of competence.”(p. 4). Black and Wiliam, 1998 Black, P., &amp; Wiliam, D. (1998). Assessment and Classroom Learning. Assessment in Education: Principles, Policy &amp; Practice, 5(1), 7–74. https://doi.org/10/fpnss4 major review of the literature on formative assessment describe formative assessment as encouraging gains in achievement that were &gt; among the largest ever reported for educational interventions (p. 61) Pellegrino et al., 2001 Pellegrino, J. W., Chudowsky, N., &amp; Glaser, R. (2001). Knowing What Students Know: The Science and Design of Educational Assessment. National Academies Press. https://doi.org/10.17226/10019 “a process of drawing reasonable inferences about what students know on the basis of evidence derived from observations of what they say, do, or make in selected situations” (p. 112) “reasoning from evidence” (p. 43) Assessment Triangle Figure 2. Assessment Triangle from Pellegrino et al. (2001) Cognition a cognitive model of the domain Observation a performance task used to gather data regarding learner achievement Interpretation an inference or judgement of the learner’s achievement in relation to the model of the domain Approaches to Learning Biggs, 1993 Biggs, J. B. (1993). From Theory to Practice: A Cognitive Systems Approach. Higher Education Research &amp; Development, 12(1), 73–85. https://doi.org/10/ccdmd9 Figure 3. 3-P Model of Teaching and Learning adapted from Biggs (1993) Presage factors that precede learning activities learner factors prior knowledge educational experience affective states wellness (physical &amp; mental) teacher factors vertical &amp; horizontal discourses (Bernstein, 1999) institutional policies department norms educational experiences Process learning focused activities reading, writing, discussing, building, creating, synthesizing, researching, sharing, debating, publishing… surface approaches using low-level cognitive skills when high-level cognitive skills are required deep approaches using high-level cognitive skills for tasks which require them Product learner achievement of outcomes (intended or emergent) fed back into the system informs learners and instructors Conceptions of Assessment Brown, 1994; 1996 Brown, G. T. L. (2004). Teachers’ conceptions of assessment: Implications for policy and professional development. Assessment in Education: Principles, Policy &amp; Practice, 11(3), 301–318. https://doi.org/10.1080/0969594042000304609 Brown, G. T. L. (2006). Teachers’ Conceptions of Assessment: Validation of an Abridged Version. Psychological Reports, 99(1), 166–170. https://doi.org/10/bf67hf general mental structure, encompassing beliefs, meanings, concepts, propositions, rules, mental images, preferences improvement of teaching and learning, school accountability, student accountability, or treating assessment as irrelevant. Fletcher et al., 2012 Fletcher, R. B., Meyer, L. H., Anderson, H., Johnston, P., &amp; Rees, M. (2012). Faculty and Students Conceptions of Assessment in Higher Education. Higher Education, 64(1), 119–133. https://doi.org/10/ctccpq instructors were more likely than learners to view assessment as consistent and trustworthy methods to understand and improve learning learners were more likely to have negative views of assessment and viewed it as a measure of student and institutional accountability. Earl, 2013 Earl, L. M. (2013). Assessment as learning: Using classroom assessment to maximize student learning (Second edition). Corwin Press. Assessment OF Learning summative Assessment FOR Learning formative Assessment AS Learning metacognitive Approaches to Assessment Both learning and assessment are complex phenomena which are impacted by myriad factors. Shepard (2000) Shepard, L. A. (2000). The Role of Assessment in a Learning Culture. Educational Researcher, 29(7), 4–14. https://doi.org/10/cw9jwc traditional assessment structures originated in behaviourist models of teaching and learning emphasis on culture of summative assessment modern constructivist models of teaching and learning are less compatible with previous assessment structures, yet a culture that emphasizes summative assessment seems to persist alongside emerging models of assessment DeLuca, 2016 DeLuca, C., LaPointe-McEwan, D., &amp; Luhanga, U. (2016). Approaches to classroom assessment inventory: A new instrument to support teacher assessment literacy. Educational Assessment, 21, 248–266. https://doi.org/10/gfgtsg Figure 4. Approaches to Classroom Assessment from DeLuca et al. (2016) Approaches to Classroom Assessment Inventory designed to inventory K12 teachers’ thoughts, beliefs, actions related to assessment Assessment purpose (of, for, as learning) Assessment process (design, use/scoring, communication) Assessment fairness (standard, equitable, differentiated) Assessment theory (consistent, balanced, contextual) Technology-Mediated Assessment in Higher Education Contrasting with K12 There is a very large body of literature on assessment in K12 learning contexts, and a not-quite as large, but still substantial body of literature on assessment in higher education. It may be tempting to conflate the two contexts, but K12 teachers typically complete 2 full years of pedagogical training as part of their academic and practical preparation. These two years often include specific courses on assessment, learning theory, as well as domain-specific pedagogies. On the other hand, higher education instructors (from part-time sessionals to adjuncts to tenure-track and tenured faculty) tend to engage in little academic preparation in learning theories or assessment, although they seem to absorb the signature pedagogies of their discipline. Impact of Technology Impact on higher education is ubiquitous (SIS, LMS/VLE, CRM, etc.) Tends to emphasize efficiency (however ill-defined that may be) doing the same things with greater speed and/or reduced effort reinscribes mis-aligned assessment structures Pockets of Innovation Bearman et al. 2020 Bearman, M., Dawson, P., Ajjawi, R., Tai, J., &amp; Boud, D. (Eds.). (2020). Re-imagining university assessment in a digital world. Springer. cognitive offloading artificial intelligence “personalized” learning; recommender systems, automated item generation, automated essay scoring dialogic feedback video, audio, screencast data &amp; learning analytics process data peer/self-assessment micro-credentials However… critical to consider ethical and social impacts! surveillance equity algorithmic assessment Bower, 2019 Bower, M. (2019). Technology‐mediated learning theory. British Journal of Educational Technology, 50(3), 1035–1048. https://doi.org/10.1111/bjet.12771 In technology-mediated learning contexts, agentic intentions reside with humans, and not with technology. 3 (select) premises technology mediates between learners and outcomes beliefs, knowledge, practices, and environment are mutually influential (add this to the complexity of assessment) role of teachers is to optimise learning through the purposeful deployment of learning technologies Revisiting Shepard (2000) Using hypothes.is 22 years have passed… What has changed? What is your experience of technology-mediated assessment in higher education? What are your greatest challenges related to technology-mediated assessment? Themes and Research Directions assessment as conversation in digital environments validity exploration of Approaches to Assessment in higher ed. humanizing assessment, ethics Questions? Comments? References Bearman, M., Dawson, P., Ajjawi, R., Tai, J., &amp; Boud, D. (Eds.). (2020). Re-imagining university assessment in a digital world. Springer. Bernstein, B. (1999). Vertical and Horizontal Discourse: An Essay. British Journal of Sociology of Education, 20(2), 157–173. JSTOR. https://doi.org/10/ftmsvc Biggs, J. B. (1993). From Theory to Practice: A Cognitive Systems Approach. Higher Education Research &amp; Development, 12(1), 73–85. https://doi.org/10/ccdmd9 Black, P., &amp; Wiliam, D. (1998). Assessment and Classroom Learning. Assessment in Education: Principles, Policy &amp; Practice, 5(1), 7–74. https://doi.org/10/fpnss4 Bloom, B. (1968). Learning for Mastery. Instruction and Curriculum. Regional Education Laboratory for the Carolinas and Virginia, Topical Papers and Reprints, Number 1. Evaluation Comment, 1(2), 12. Bower, M. (2019). Technology‐mediated learning theory. British Journal of Educational Technology, 50(3), 1035–1048. https://doi.org/10.1111/bjet.12771 Brown, G. T. L. (2004). Teachers’ conceptions of assessment: Implications for policy and professional development. Assessment in Education: Principles, Policy &amp; Practice, 11(3), 301–318. https://doi.org/10.1080/0969594042000304609 Brown, G. T. L. (2006). Teachers’ Conceptions of Assessment: Validation of an Abridged Version. Psychological Reports, 99(1), 166–170. https://doi.org/10/bf67hf DeLuca, C., LaPointe-McEwan, D., &amp; Luhanga, U. (2016). Approaches to classroom assessment inventory: A new instrument to support teacher assessment literacy. Educational Assessment, 21, 248–266. https://doi.org/10/gfgtsg DeLuca, C., Willis, J., Cowie, B., Harrison, C., Coombs, A., Gibson, A., &amp; Trask, S. (2019). Policies, Programs, and Practices: Exploring the Complex Dynamics of Assessment Education in Teacher Education Across Four Countries. Frontiers in Education, 4, 132. https://doi.org/10/gh5k2r Earl, L. M. (2013). Assessment as learning: Using classroom assessment to maximize student learning (Second edition). Corwin Press. Fletcher, R. B., Meyer, L. H., Anderson, H., Johnston, P., &amp; Rees, M. (2012). Faculty and Students Conceptions of Assessment in Higher Education. Higher Education, 64(1), 119–133. https://doi.org/10/ctccpq Mislevy, R. J. (1994). Test theory reconcieved. ETS Research Report Series, 1994(1), i–38. https://doi.org/10/gjm236 Pellegrino, J. W., Chudowsky, N., &amp; Glaser, R. (2001). Knowing What Students Know: The Science and Design of Educational Assessment. National Academies Press. https://doi.org/10.17226/10019 Scriven, M. (1967). The methodology of evaluation. In B. O. Smith (Ed.), Perspectives of curriculum evaluation. Rand McNally Shepard, L. A. (2000). The Role of Assessment in a Learning Culture. Educational Researcher, 29(7), 4–14. https://doi.org/10/cw9jwc "],["twu-faculty-professional-learning.html", " 2 TWU Faculty Professional Learning 2.1 What is ‘assessment’? 2.2 Thinking about your Approach to Assessment", " 2 TWU Faculty Professional Learning Colin Madland, Manager, Online Learning and Instructional Technology (TWU GLOBAL) PhD Candidate, University of Victoria Notes - https://bit.ly/twu-assessment QR Code to access presentation notes Find me on the web… Twitter Mastodon Presented Online for TWU Faculty Professional Learning, Thursday, March 9, 2023 I acknowledge that the land where I currently live and work remains the traditional, ancestral, and unceded land of the syilx (silks) people, whose historical stewardship of and connections to the land continue to today. I am grateful to be an uninvited guest on this land. To learn more, please visit the syilx.org. My blind dog, Eleanor near the top of Mission Hill, overlooking syilx territory. 2.1 What is ‘assessment’? Pellegrino, J. W., Chudowsky, N., &amp; Glaser, R. Knowing What Students Know: The Science and Design of Educational Assessment. National Academies Press. https://doi.org/10.17226/10019 “reasoning from evidence” (p. 43) “a process of drawing reasonable inferences about what students know on the basis of evidence derived from observations of what they say, do, or make in selected situations” (p. 112) 2.2 Thinking about your Approach to Assessment Scenario 1 You are teaching a large enrollment course. The students will be submitting bi-weekly assignments, a midterm exam, and a culminating assignment all designed to support their learning. Grade each bi-weekly assignment. Read a subset of bi-weekly assignments, identify and share performance trends with the whole class. Ask students to self-assess their bi-weekly assignments using evaluative criteria. Use performance trends from the bi-weekly assignments to inform the redesign of the midterm or culminating assessment. Develop a rubric or scoring guide to assess the culminating assignment in advance of student submissions. Dedicate class time to discuss students’ performance trends from the midterm and address gaps in learning so students are better prepared for the culminating assignment. Have every student complete the same culminating assignment using the same scoring rubric or guide. Have all students complete the same culminating assignment with formal accommodations for students who require them. Provide students with a choice of three different culminating assignments that assess the same learning goals. Consistently apply late submission policies for all students when generating grades. Consider each student’s individual circumstances when deciding how to apply late submission policies. Use the late submission policy as a guideline to ensure a consistent principle is applied while also using professional judgement for students with individual circumstances. If your response to this scenario was not listed above, how would you most likely respond? Scenario 2 A core assignment in your course involves students working in groups online. Grade the assignment solely based on the group’s final product. Engage students in an ongoing peer feedback process to enhance group collaboration. Engage students in self-assessment to increase their accountability and engagement in the assignment. Leverage online design features to engage students in peer feedback and self-assessment. Take group member feedback into consideration when generating final grades. Communicate grading decisions based on evaluation criteria and evidence of student learning. Give all group members the same grade. Monitor barriers to a student’s performance in group work (e.g., language, technology) and grade accordingly. Grade each student individually based on their contribution to the group’s process and product. Use the same rubric to consistently grade all groups’ assignments. Modify and apply the rubric differently in response to unexpected group events (e.g., group member leaves). Use the same rubric, but consider group composition, size, and cohesion when grading. If your response to this scenario was not listed above, how would you most likely respond? Scenario 3 There are expectations in your department that grades should be distributed across the grading scale. However, your class averages are consistently lower than your colleagues’. Your course assessment scheme includes two term exams and one final exam. Provide students with additional graded assessments to chunk learning into smaller units. Provide students with additional opportunities to check their understanding throughout the course (e.g., ungraded quizzes, exit slips). Provide self-assessment opportunities to help students recognize and address gaps in their learning. Analyze exam results to determine if weak performance was due to exam design issues. Remove exam questions that most students struggled with and re-calculate student scores. Schedule class time to review exam performance to address learning gaps. Shift all exam grades up so averages are consistent with departmental colleagues. Provide students who performed below the class average with the opportunity to rewrite an equivalent exam. Provide any student the opportunity to rewrite an equivalent exam. Analyze the consistency of student performance across course exams. Analyze exam questions to ensure alignment with taught content. Analyze how students performed on exams in relation to taught content. If your response to this scenario was not listed above, how would you most likely respond? Scenario 4 You teach a course with multiple sections taught by various instructors. Your students have complained to you that assignments are constructed and graded differently across sections. Explain to students that while learning outcomes are the same across sections, grades are based on their individual performance on assignments. Ensure students have the opportunity to receive feedback prior to submitting assignments to increase their focus on learning over grades. Invite students to reflect on their personal learning goals for the course so they can plan for their own success in your course. Engage in a collaborative design process with other instructors to set standards and design common assignments. Collaboratively score a subset of assignments with the other instructors to ensure consistent use of scoring guides across sections. Communicate your grading approach to your students and explain how it aligns with intended learning goals. Propose a standard approach to assignments and grading be applied across all sections. Assure students that while the assignments may be different across the sections, they assess the same learning outcomes. Offer students the opportunity to select and complete an assignment from another section. Work with the other instructors to revise all assignments across sections so they are all the same. Justify differences in approaches to assessment based on instructor orientations to assessment, teaching context, and students’ learning needs. Recognize student concerns and engage in practices that ensure your assignments are equivalent to those in other sections. If your response to this scenario was not listed above, how would you most likely respond? Scenario 5 You discover that a student has plagiarized some of their assignment (e.g., an essay, lab report). Give the student a 0 on the assignment. Have the student re-write the plagiarized section in their own words, then re-grade the assignment. Ask the students to reflect on why plagiarism is a problem and what they would do differently next time. As the instructor, reflect on how the assignment could have been structured differently to deter plagiarism. Adjust the student’s grade to reflect the portion of work that was plagiarized. Discuss with the student the reasons for the plagiarism, severity of plagiarism, and negotiate potential next steps for their learning. Apply the same consequence you would for other students to ensure all students are treated the same. Consider if the student has identified accommodations before determining response to plagiarism. Discuss why the student plagiarized and agree upon an appropriate alternative assignment. Apply all aspects of institutional policy on academic integrity to ensure consistency across all students. Consider the original aspects of the assignment and the plagiarized text to determine what the student knows and does not appear to know related to learning outcomes. Consider extenuating circumstances surrounding the plagiarism and use professional judgement when applying the institutional academic integrity policy. If your response to this scenario was not listed above, how would you most likely respond? The Scenarios and responses above are from DeLuca, C., LaPointe-McEwan, D., &amp; Luhanga, U. (2016). Approaches to classroom assessment inventory: A new instrument to support teacher assessment literacy. Educational Assessment, 21, 248–266. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
